{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.remote.webelement import WebElement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver = Chrome()\n",
    "webdriver.get(\"https://www.instagram.com/\")\n",
    "\n",
    "# need login first, so wait for user to login\n",
    "# time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-10-14 02:27:12] [INFO] Logger setup complete\n"
     ]
    }
   ],
   "source": [
    "class CustomFormatter(logging.Formatter):\n",
    "    log_format = \"[%(asctime)s] [%(levelname)s] %(message)s\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(self.log_format, datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "# remove any existing handlers to prevent double logging\n",
    "if logging.getLogger().hasHandlers():\n",
    "    logging.getLogger().handlers.clear()\n",
    "\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(CustomFormatter())\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "\n",
    "def log_func(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        logger.info(f\"[{func.__name__}]\")\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "logger.info(\"Logger setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_func\n",
    "def show_first_post(url: str):\n",
    "    try:\n",
    "        webdriver.get(url)\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(webdriver.page_source, \"html.parser\")\n",
    "        divs = soup.find_all(\n",
    "            \"div\",\n",
    "            class_=\"x1lliihq x1n2onr6 xh8yej3 x4gyw5p xfllauq xo2y696 x11i5rnm x2pgyrj\",\n",
    "        )\n",
    "        list_urls = []\n",
    "\n",
    "        for div in divs:\n",
    "            a_tag = div.find(\"a\", recursive=False)\n",
    "            if a_tag and \"href\" in a_tag.attrs:\n",
    "                list_urls.append(a_tag[\"href\"])\n",
    "\n",
    "        element = webdriver.find_element(By.XPATH, f'//a[@href=\"{list_urls[0]}\"]')\n",
    "        element.click()\n",
    "    except Exception as e:\n",
    "        logger.error(str(e).split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_func\n",
    "def get_caption() -> Optional[str]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(webdriver.page_source, \"html.parser\")\n",
    "        divs = soup.find_all(\"div\", class_=\"_a9zs\")\n",
    "        for div in divs:\n",
    "            h1_tag = div.find(\n",
    "                \"h1\", class_=\"_ap3a _aaco _aacu _aacx _aad7 _aade\", recursive=False\n",
    "            )\n",
    "            for br in h1_tag.find_all(\"br\"):\n",
    "                br.replace_with(\"\\n\")\n",
    "            if h1_tag:\n",
    "                return h1_tag.text\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(str(e).split(\"\\n\")[0])\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_element_xpath(element: WebElement) -> Optional[str]:\n",
    "    try:\n",
    "        full_xpath = webdriver.execute_script(\n",
    "            \"\"\"\n",
    "            function getElementXPath(element) {\n",
    "                if (element.id !== '') {\n",
    "                    return 'id(\"' + element.id + '\")';\n",
    "                }\n",
    "                if (element === document.body) {\n",
    "                    return element.tagName.toLowerCase();\n",
    "                }\n",
    "\n",
    "                let ix = 0;\n",
    "                const siblings = element.parentNode.childNodes;\n",
    "                let sameTagSiblings = 0;\n",
    "\n",
    "                for (let i = 0; i < siblings.length; i++) {\n",
    "                    if (siblings[i].nodeType === 1 && siblings[i].tagName === element.tagName) {\n",
    "                        sameTagSiblings++;\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                for (let i = 0; i < siblings.length; i++) {\n",
    "                    const sibling = siblings[i];\n",
    "                    if (sibling === element) {\n",
    "                        let text = \"\";\n",
    "                        \n",
    "                        if (sameTagSiblings > 1) {\n",
    "                            text = '[' + (ix + 1) + ']';\n",
    "                        }\n",
    "                        \n",
    "                        return getElementXPath(element.parentNode) + '/' + element.tagName.toLowerCase() + text;\n",
    "                    }\n",
    "\n",
    "                    if (sibling.nodeType === 1 && sibling.tagName === element.tagName) {\n",
    "                        ix++;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            return getElementXPath(arguments[0]);\n",
    "\n",
    "        \"\"\",\n",
    "            element,\n",
    "        )\n",
    "        result = f\"/html/{full_xpath}\"\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(str(e).split(\"\\n\")[0])\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_func\n",
    "def load_more_comments():\n",
    "    try:\n",
    "        title = webdriver.find_element(\n",
    "            By.XPATH, \"//*[contains(text(), 'Load more comments')]\"\n",
    "        )\n",
    "        if title:\n",
    "            is_found = True\n",
    "            while is_found:\n",
    "                try:\n",
    "                    title = webdriver.find_element(\n",
    "                        By.XPATH, \"//*[contains(text(), 'Load more comments')]\"\n",
    "                    )\n",
    "                    title_xpath = _get_element_xpath(title)\n",
    "                    button_xpath = title_xpath[\n",
    "                        : title_xpath.rfind(\"button\") + len(\"button\")\n",
    "                    ]\n",
    "                    try:\n",
    "                        button_element = webdriver.find_element(By.XPATH, button_xpath)\n",
    "                        button_element.click()\n",
    "                    except Exception as e:\n",
    "                        logger.error(str(e).split(\"\\n\")[0])\n",
    "                        is_found = False\n",
    "                except Exception as e:\n",
    "                    logger.error(str(e).split(\"\\n\")[0])\n",
    "                    is_found = False\n",
    "    except Exception as e:\n",
    "        logger.error(str(e).split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_func\n",
    "def show_replies():\n",
    "    try:\n",
    "\n",
    "        button = webdriver.find_elements(\n",
    "            \"xpath\", \"//button[contains(@class, '_acan _acao _acas _aj1- _ap30')]\"\n",
    "        )\n",
    "        result_button = [\n",
    "            b\n",
    "            for b in button\n",
    "            if (b.text.startswith(\"View replies\") or b.text.startswith(\"View all\"))\n",
    "        ]\n",
    "        total_button = len(result_button)\n",
    "        if total_button > 0:\n",
    "            for b in result_button:\n",
    "                b.click()\n",
    "            logger.info(f\"Total button clicked: {total_button}\")\n",
    "        else:\n",
    "            logger.warning(\"No replies found\")\n",
    "    except Exception as e:\n",
    "        logger.error(str(e).split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_func\n",
    "def get_comments() -> list[str]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(webdriver.page_source, \"html.parser\")\n",
    "        comments = soup.find_all(\"div\", class_=\"_a9zs\")\n",
    "        result = []\n",
    "        for div in comments:\n",
    "            span_tag = div.find(\n",
    "                \"span\", class_=\"_ap3a _aaco _aacu _aacx _aad7 _aade\", recursive=False\n",
    "            )\n",
    "            if span_tag:\n",
    "                result.append(span_tag.text)\n",
    "        logger.info(f\"Total comments found: {len(result)}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(str(e).split(\"\\n\")[0])\n",
    "        return list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_func\n",
    "def next_post():\n",
    "    try:\n",
    "        button = webdriver.find_element(\n",
    "            By.XPATH,\n",
    "            f'//span[@style=\"display: inline-block; transform: rotate(90deg);\"]',\n",
    "        )\n",
    "        button.click()\n",
    "    except Exception as e:\n",
    "        logger.error(str(e).split(\"\\n\")[0])\n",
    "\n",
    "\n",
    "@log_func\n",
    "def has_next_post() -> bool:\n",
    "    try:\n",
    "        webdriver.find_element(\n",
    "            By.XPATH,\n",
    "            f'//span[@style=\"display: inline-block; transform: rotate(90deg);\"]',\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(str(e).split(\"\\n\")[0])\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict\n",
    "\n",
    "\n",
    "class PostResult(TypedDict):\n",
    "    caption: str\n",
    "    comments: List[str]\n",
    "\n",
    "\n",
    "class Dataset(TypedDict):\n",
    "    data: Dict[str, PostResult]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_func\n",
    "def _get_single_post_data() -> PostResult:\n",
    "    load_more_comments()\n",
    "    show_replies()\n",
    "    caption = get_caption()\n",
    "    comments = get_comments()\n",
    "    return PostResult(caption=caption, comments=comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_instagram(username: str, post: Optional[int] = -1) -> Dataset:\n",
    "    try:\n",
    "        if post == 0:\n",
    "            return\n",
    "\n",
    "        result = Dataset(data={})\n",
    "        url = f\"https://www.instagram.com/{username}/\"\n",
    "        show_first_post(url)\n",
    "\n",
    "        # get data\n",
    "        post_data = _get_single_post_data()\n",
    "        # 'https://www.instagram.com/p/:POST_ID/?img_index=1'\n",
    "        post_id = webdriver.current_url.split(\"/\")[4]\n",
    "        result.get(\"data\").update({post_id: post_data})\n",
    "\n",
    "        if post == -1:\n",
    "            while has_next_post():\n",
    "                next_post()\n",
    "                time.sleep(2)\n",
    "                post_data = _get_single_post_data()\n",
    "                post_id = webdriver.current_url.split(\"/\")[4]\n",
    "                result.get(\"data\").update({post_id: post_data})\n",
    "        else:\n",
    "            while post and has_next_post():\n",
    "                next_post()\n",
    "                post -= 1\n",
    "                time.sleep(2)\n",
    "                post_data = _get_single_post_data()\n",
    "                post_id = webdriver.current_url.split(\"/\")[4]\n",
    "                result.get(\"data\").update({post_id: post_data})\n",
    "            if post:\n",
    "                logger.warning(\"Total post less than expected\")\n",
    "\n",
    "        # stats\n",
    "        total_post = len(result.get(\"data\"))\n",
    "        total_comments = sum(\n",
    "            len(post.get(\"comments\")) for post in result.get(\"data\").values()\n",
    "        )\n",
    "        logger.info(f\"Total post scraped: {total_post}\")\n",
    "        logger.info(f\"Total comments scraped: {total_comments}\")\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(str(e).split(\"\\n\")[0])\n",
    "        return Dataset(data={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-10-14 02:27:19] [INFO] [show_first_post]\n",
      "[2024-10-14 02:27:23] [INFO] [_get_single_post_data]\n",
      "[2024-10-14 02:27:23] [INFO] [load_more_comments]\n",
      "[2024-10-14 02:27:23] [ERROR] Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[contains(text(), 'Load more comments')]\"}\n",
      "[2024-10-14 02:27:23] [INFO] [show_replies]\n",
      "[2024-10-14 02:27:23] [WARNING] No replies found\n",
      "[2024-10-14 02:27:23] [INFO] [get_caption]\n",
      "[2024-10-14 02:27:23] [INFO] [get_comments]\n",
      "[2024-10-14 02:27:23] [INFO] Total comments found: 0\n",
      "[2024-10-14 02:27:23] [INFO] [has_next_post]\n",
      "[2024-10-14 02:27:24] [INFO] [next_post]\n",
      "[2024-10-14 02:27:26] [INFO] [_get_single_post_data]\n",
      "[2024-10-14 02:27:26] [INFO] [load_more_comments]\n",
      "[2024-10-14 02:27:26] [ERROR] Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[contains(text(), 'Load more comments')]\"}\n",
      "[2024-10-14 02:27:26] [INFO] [show_replies]\n",
      "[2024-10-14 02:27:26] [INFO] Total button clicked: 1\n",
      "[2024-10-14 02:27:26] [INFO] [get_caption]\n",
      "[2024-10-14 02:27:26] [INFO] [get_comments]\n",
      "[2024-10-14 02:27:26] [INFO] Total comments found: 4\n",
      "[2024-10-14 02:27:26] [INFO] [has_next_post]\n",
      "[2024-10-14 02:27:26] [INFO] [next_post]\n",
      "[2024-10-14 02:27:29] [INFO] [_get_single_post_data]\n",
      "[2024-10-14 02:27:29] [INFO] [load_more_comments]\n",
      "[2024-10-14 02:27:29] [ERROR] Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[contains(text(), 'Load more comments')]\"}\n",
      "[2024-10-14 02:27:29] [INFO] [show_replies]\n",
      "[2024-10-14 02:27:29] [WARNING] No replies found\n",
      "[2024-10-14 02:27:29] [INFO] [get_caption]\n",
      "[2024-10-14 02:27:29] [INFO] [get_comments]\n",
      "[2024-10-14 02:27:29] [INFO] Total comments found: 0\n",
      "[2024-10-14 02:27:29] [INFO] [has_next_post]\n",
      "[2024-10-14 02:27:29] [INFO] [next_post]\n",
      "[2024-10-14 02:27:31] [INFO] [_get_single_post_data]\n",
      "[2024-10-14 02:27:31] [INFO] [load_more_comments]\n",
      "[2024-10-14 02:27:31] [ERROR] Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[contains(text(), 'Load more comments')]\"}\n",
      "[2024-10-14 02:27:31] [INFO] [show_replies]\n",
      "[2024-10-14 02:27:31] [WARNING] No replies found\n",
      "[2024-10-14 02:27:31] [INFO] [get_caption]\n",
      "[2024-10-14 02:27:31] [INFO] [get_comments]\n",
      "[2024-10-14 02:27:31] [INFO] Total comments found: 0\n",
      "[2024-10-14 02:27:31] [INFO] [has_next_post]\n",
      "[2024-10-14 02:27:31] [INFO] [next_post]\n",
      "[2024-10-14 02:27:33] [INFO] [_get_single_post_data]\n",
      "[2024-10-14 02:27:33] [INFO] [load_more_comments]\n",
      "[2024-10-14 02:27:33] [ERROR] Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[contains(text(), 'Load more comments')]\"}\n",
      "[2024-10-14 02:27:33] [INFO] [show_replies]\n",
      "[2024-10-14 02:27:34] [INFO] Total button clicked: 1\n",
      "[2024-10-14 02:27:34] [INFO] [get_caption]\n",
      "[2024-10-14 02:27:34] [INFO] [get_comments]\n",
      "[2024-10-14 02:27:34] [INFO] Total comments found: 2\n",
      "[2024-10-14 02:27:34] [INFO] [has_next_post]\n",
      "[2024-10-14 02:27:34] [INFO] [next_post]\n",
      "[2024-10-14 02:27:36] [INFO] [_get_single_post_data]\n",
      "[2024-10-14 02:27:36] [INFO] [load_more_comments]\n",
      "[2024-10-14 02:27:36] [ERROR] Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[contains(text(), 'Load more comments')]\"}\n",
      "[2024-10-14 02:27:36] [INFO] [show_replies]\n",
      "[2024-10-14 02:27:36] [WARNING] No replies found\n",
      "[2024-10-14 02:27:36] [INFO] [get_caption]\n",
      "[2024-10-14 02:27:37] [INFO] [get_comments]\n",
      "[2024-10-14 02:27:37] [INFO] Total comments found: 15\n",
      "[2024-10-14 02:27:37] [INFO] [has_next_post]\n",
      "[2024-10-14 02:27:37] [INFO] [next_post]\n",
      "[2024-10-14 02:27:39] [INFO] [_get_single_post_data]\n",
      "[2024-10-14 02:27:39] [INFO] [load_more_comments]\n",
      "[2024-10-14 02:27:39] [ERROR] Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[contains(text(), 'Load more comments')]\"}\n",
      "[2024-10-14 02:27:39] [INFO] [show_replies]\n",
      "[2024-10-14 02:27:39] [WARNING] No replies found\n",
      "[2024-10-14 02:27:39] [INFO] [get_caption]\n",
      "[2024-10-14 02:27:39] [INFO] [get_comments]\n",
      "[2024-10-14 02:27:39] [INFO] Total comments found: 0\n",
      "[2024-10-14 02:27:39] [INFO] [has_next_post]\n",
      "[2024-10-14 02:27:39] [INFO] [next_post]\n",
      "[2024-10-14 02:27:42] [INFO] [_get_single_post_data]\n",
      "[2024-10-14 02:27:42] [INFO] [load_more_comments]\n",
      "[2024-10-14 02:27:42] [ERROR] Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[contains(text(), 'Load more comments')]\"}\n",
      "[2024-10-14 02:27:42] [INFO] [show_replies]\n",
      "[2024-10-14 02:27:42] [WARNING] No replies found\n",
      "[2024-10-14 02:27:42] [INFO] [get_caption]\n",
      "[2024-10-14 02:27:42] [INFO] [get_comments]\n",
      "[2024-10-14 02:27:42] [INFO] Total comments found: 4\n",
      "[2024-10-14 02:27:42] [INFO] [has_next_post]\n",
      "[2024-10-14 02:27:42] [INFO] [next_post]\n",
      "[2024-10-14 02:27:44] [INFO] [_get_single_post_data]\n",
      "[2024-10-14 02:27:44] [INFO] [load_more_comments]\n",
      "[2024-10-14 02:27:44] [ERROR] Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[contains(text(), 'Load more comments')]\"}\n",
      "[2024-10-14 02:27:44] [INFO] [show_replies]\n",
      "[2024-10-14 02:27:44] [WARNING] No replies found\n",
      "[2024-10-14 02:27:44] [INFO] [get_caption]\n",
      "[2024-10-14 02:27:44] [INFO] [get_comments]\n",
      "[2024-10-14 02:27:44] [INFO] Total comments found: 1\n",
      "[2024-10-14 02:27:44] [INFO] [has_next_post]\n",
      "[2024-10-14 02:27:44] [ERROR] Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//span[@style=\"display: inline-block; transform: rotate(90deg);\"]\"}\n",
      "[2024-10-14 02:27:44] [INFO] Total post scraped: 9\n",
      "[2024-10-14 02:27:44] [INFO] Total comments scraped: 26\n"
     ]
    }
   ],
   "source": [
    "dataset = scraping_instagram(\"putu_waw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'C3W-SslrQpp': {'caption': 'Halo seluruh mahasiswa Indonesia. Saya siap mengikuti Magang dan Studi Independen Bersertifikat Angkatan 6!',\n",
       "   'comments': []},\n",
       "  'Cv4iiXPLDl6': {'caption': 'Halo! Saya Putu Widyantara Artanta Wibawa dari Universitas Udayana siap mengikuti National Onboarding MSIB Angkatan 5!\\n\\n#BerprosesLebihBaik #KampusMerdeka #MSIB5 #MagangMerdeka #MagangBersertifikat #BukanMagangdanStudiBiasa #MSIB5',\n",
       "   'comments': ['Mangaaat', '🔥', 'Great My son😍', 'Semangat frenn🔥']},\n",
       "  'CZqhWPWlNYN': {'caption': '[SAYA SIAP MENGIKUTI MAHASISYA UPANAYANA XIX]\\n\\nOm Swastyastu 🙏\\n\"Om Ano Bhadrah Kratavo Yantu Visvatah\" - (Yajur Veda XXV. 14)\\n(Semoga pikiran yang baik datang dari segala penjuru)\\n\\nMahasisya Upanayana merupakan upacara penyucian diri dengan tujuan memohon doa restu secara niskala tatkala seorang mahasiswa akan menuntut ilmu dan berguru di Universitas Udayana.\\n\\nSaya Putu Widyantara Artanta Wibawa, Siap mengikuti Mahasisya Upanayana XIX tahun 2022. \\n\\n\"Tad viddhi praņipātena\\nParipraśneņa sēvayā\\nUpadekşyanti te jñānam\\nJñāninas tattva darśinah\"\\n(Bhagavadgita IV. 34)\\n\\n(Kejarlah kebijakan itu dengan kerendahan hati, dengan bertanya-tanya dan dengan pengabdian. Orang bijaksana yang melihat kebenaran itu akan memberi petunjuk padamu tentang pengetahuan itu).\\n\\n🙏🏻 Om Santih, Santih, Santih Om 🙏🏻\\nSatyam Eva Jayate!',\n",
       "   'comments': []},\n",
       "  'CStykH6lYRU': {'caption': \"[I'M READY FOR STUDENT DAY FMIPA 2021]\\n\\nHalo, sobat MIPA!👋\\nPerkenalkan saya Putu Widyantara Artanta Wibawa, mahasiswa Program Studi Informatika siap mengikuti Student Day FMIPA 2021. Sampai jumpa di Hari Puncak Student Day FMIPA 2021 pada tanggal 20 Agustus 2021.\\n\\nSaya MIPA, Saya Bangga!\\n\\n@bemfmipaunud @fmipaunud\\n#StudentDayFMIPAUnud2021\\n#MIPAJaya\\n#ProudToBeSilver\",\n",
       "   'comments': []},\n",
       "  'CSgDdyaLOuL': {'caption': '[PKKMB FMIPA]\\n\\nSaya Putu Widyantara Artanta Wibawa, dari Fakultas Matematika dan Ilmu Pengetahuan Alam, Prodi Informatika.\\n\\nSaya siap mengikuti PKKMB FMIPA pada tanggal 18-19 Agustus 2021.\\n\\n@fmipaunud\\n#fmipaUnud\\n#FakultasMIPAUniversitasUdayana\\n#PKKMBFMIPA2021\\n#PKKMBUNUD2021\\n#PKKMB2021',\n",
       "   'comments': ['Kepak sayap FMIPA🔥', 'Jurusan apa kau? Semangat yooo']},\n",
       "  'CSbwvz_lyUK': {'caption': '[Saya Ksatria Muda Udayana Siap Mengikuti Student Day 2021]\\n\\nJalan-jalan ke Kota Tua\\nDi Kota Tua ada Car-Free Day\\nMohon izin kakak-kakak semua\\nSaya siap ikuti Student Day\\n\\nSaya Putu Widyantara Artanta Wibawa siap mengikuti Student Day 2021 Universitas Udayana pada tanggal 12-13 Agustus 2021.\\n\\n#StudentDay2021Unud\\n#ParwataArundaya',\n",
       "   'comments': ['Semangat putu🔥🔥',\n",
       "    'mangadd kak putuww🔥',\n",
       "    'Semangat cokkk🔥',\n",
       "    'keren tuu🔥',\n",
       "    'mangatt putu!🔥🙌',\n",
       "    'Semangatt putuu🔥🔥',\n",
       "    'mangat cak caknya🔥🔥',\n",
       "    'Semangat weee🙌🔥',\n",
       "    'Mangats waww',\n",
       "    'Mangattt waw🔥🔥',\n",
       "    'Inget kiri-kanan Tuu🙏🏼🤝🏻',\n",
       "    'Ow semangat 🔥',\n",
       "    'Semangat bang 🔥',\n",
       "    'semangaatt putuu🙌🔥',\n",
       "    'MANGAT WAW🔥']},\n",
       "  'B4Uyx6FlxyM': {'caption': 'TPF20192410_007_Putu Widyantara Artanta Wibawa_Sore-Sore Ring Pelabuhan Buleleng_Objek Wisata di Bali\\n\\nSore-sore ring pelabuhan Buleleng\\nPemandangan yukti lintang asri\\nOmbak ane menepi pesisi\\nRikala Sang Surya jagi pineleb.\\nKutipan lagu karya Gede Darma ini menjadi saksi keindahan Eks Pelabuhan Buleleng yang pernah menjadi dermaga terbesar di Pulau Bali sebelum pusat pemerintah Provinsi Bali dipindah ke Bali Selatan.\\n\\nDi kawasan Eks Pelabuhan Buleleng dibangun monumen Yudha Mandala untuk mengenang perjuangan rakyat Bali disaat berjuang melawan  penjajahan Belanda. \\nKayu-kayu bekas yang berumur tua di dermaga ini dirubah menjadi restoran terapung yang memiliki desain yang unik dengan panorama pantai yang berpadu dengan deburan ombak serta semilir angin yang berhembus lembut menerpa tubuh.\\n\\nInilah Eks Pelabuhan Buleleng yang sekarang, dengan sajian keindahannya yang begitu memesona dan sarat akan nilai sejarah. [Keterangan Teknis]\\nDevice : OPPO F7\\nFocal Length : 3.62 mm\\nAperture : f/1.8\\nISO : 40\\nFlash : No flash\\nWhite Balance : Auto\\nExposure Time : 1/374 s\\n[Tags]\\n@odowkun_ @pringga_arts @rosyanaputra_ @hima_tp_undiksha #tpfotografi2019 #himatpundiksha',\n",
       "   'comments': []},\n",
       "  'BRhg04YjO0w': {'caption': 'Landscape Photography by : @putu_waw. This photo took on Sunday, 12 March 2017 at 06.20 (GMT + 8).',\n",
       "   'comments': ['So nicee',\n",
       "    '#travel',\n",
       "    'Pretty cool!',\n",
       "    'GREAT TRAVEL...Like it a lot 🤗.']},\n",
       "  'BPwIVQzBJ6t': {'caption': 'Landscape Photography by : @putu_waw. This photo took on Wednesday, 14 December 2016 at 05 : 53 (GMT + 8).',\n",
       "   'comments': ['👌']}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_dataset(file_path: str) -> Dataset:\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            return Dataset(**data)\n",
    "    except Exception as e:\n",
    "        logger.error(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# existing_dataset = get_existing_dataset(\"dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dataset = existing_dataset.copy()\n",
    "# new_dataset.get(\"data\").update(dataset.get(\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
